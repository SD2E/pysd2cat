{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from collections import OrderedDict, Counter\n",
    "from tensorflow.python.ops import gen_array_ops\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation, AveragePooling2D\n",
    "from names import Names as n\n",
    "from scipy.stats import gaussian_kde\n",
    "from descartes import PolygonPatch\n",
    "import alphashape\n",
    "from sklearn.cluster import KMeans\n",
    "from pathlib import Path\n",
    "from harness.test_harness_class import TestHarness\n",
    "from harness.th_model_instances.hamed_models.random_forest_classification import random_forest_classification\n",
    "from harness.th_model_instances.hamed_models.weighted_logistic import weighted_logistic_classifier\n",
    "from notebook_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 10000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "matplotlib.use(\"tkagg\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_idx = OrderedDict([(n.label, 0), (\"inducer_concentration\", 1), (\"timepoint\", 2), (\"percent_live\", 3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"experiment_data/processed/final_strateos_sample.csv\")\n",
    "color_channel_to_use = \"RL1\"\n",
    "use_stain_in_AutoGater = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0    270000\n",
       "3.0    270000\n",
       "0.5    270000\n",
       "Name: timepoint, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"timepoint\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.loc[data[\"stain\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features that we will use: ['FSC-A', 'FSC-H', 'FSC-W', 'SSC-A', 'SSC-H', 'SSC-W', 'RL1-A', 'RL1-H', 'RL1-W']\n"
     ]
    }
   ],
   "source": [
    "stain_cols = [\"{}-A\".format(color_channel_to_use), \n",
    "              \"{}-H\".format(color_channel_to_use),\n",
    "              \"{}-W\".format(color_channel_to_use)]\n",
    "all_features = n.morph_cols + stain_cols\n",
    "\n",
    "if use_stain_in_AutoGater:\n",
    "    features = all_features\n",
    "else:\n",
    "    features = n.morph_cols\n",
    "    \n",
    "print(\"Features that we will use: {}\".format(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our equivalent of \"samples\" will be timepoint + concentration \n",
    "(maybe add replicates later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: sample-level prediction of >50% CFU percent_live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inducer_concentration</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>FSC-A</th>\n",
       "      <th>FSC-H</th>\n",
       "      <th>FSC-W</th>\n",
       "      <th>SSC-A</th>\n",
       "      <th>SSC-H</th>\n",
       "      <th>SSC-W</th>\n",
       "      <th>RL1-A</th>\n",
       "      <th>RL1-H</th>\n",
       "      <th>RL1-W</th>\n",
       "      <th>percent_live</th>\n",
       "      <th>cfu_live</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.025396</td>\n",
       "      <td>4.909829</td>\n",
       "      <td>1.653213</td>\n",
       "      <td>4.694781</td>\n",
       "      <td>4.554477</td>\n",
       "      <td>1.556303</td>\n",
       "      <td>1.278754</td>\n",
       "      <td>2.130334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.776667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.902123</td>\n",
       "      <td>4.802822</td>\n",
       "      <td>1.612784</td>\n",
       "      <td>4.632214</td>\n",
       "      <td>4.491474</td>\n",
       "      <td>1.531479</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>2.120574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.776667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.250283</td>\n",
       "      <td>4.892784</td>\n",
       "      <td>1.919078</td>\n",
       "      <td>4.977938</td>\n",
       "      <td>4.585133</td>\n",
       "      <td>1.826075</td>\n",
       "      <td>2.292256</td>\n",
       "      <td>2.252853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.776667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.001284</td>\n",
       "      <td>4.810011</td>\n",
       "      <td>1.662758</td>\n",
       "      <td>4.677525</td>\n",
       "      <td>4.501812</td>\n",
       "      <td>1.568202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.037426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.776667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.865702</td>\n",
       "      <td>4.775749</td>\n",
       "      <td>1.602060</td>\n",
       "      <td>4.513697</td>\n",
       "      <td>4.420022</td>\n",
       "      <td>1.477121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.568202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.776667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404995</th>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.256164</td>\n",
       "      <td>3.546172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.257679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.763428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404996</th>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.509337</td>\n",
       "      <td>3.339451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>2.887617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.012837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404997</th>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.814527</td>\n",
       "      <td>3.656098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.747412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.654177</td>\n",
       "      <td>2.158362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404998</th>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.364176</td>\n",
       "      <td>3.334051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.061075</td>\n",
       "      <td>3.186674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.133539</td>\n",
       "      <td>2.416641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404999</th>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.603253</td>\n",
       "      <td>3.421439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.450249</td>\n",
       "      <td>2.725912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.307496</td>\n",
       "      <td>2.356026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        inducer_concentration  timepoint     FSC-A     FSC-H     FSC-W     SSC-A     SSC-H     SSC-W     RL1-A     RL1-H  RL1-W  percent_live  cfu_live\n",
       "0                         0.0        0.5  5.025396  4.909829  1.653213  4.694781  4.554477  1.556303  1.278754  2.130334    0.0     98.776667         1\n",
       "1                         0.0        0.5  4.902123  4.802822  1.612784  4.632214  4.491474  1.531479  0.477121  2.120574    0.0     98.776667         1\n",
       "2                         0.0        0.5  5.250283  4.892784  1.919078  4.977938  4.585133  1.826075  2.292256  2.252853    0.0     98.776667         1\n",
       "3                         0.0        0.5  5.001284  4.810011  1.662758  4.677525  4.501812  1.568202  0.000000  2.037426    0.0     98.776667         1\n",
       "4                         0.0        0.5  4.865702  4.775749  1.602060  4.513697  4.420022  1.477121  0.000000  1.568202    0.0     98.776667         1\n",
       "...                       ...        ...       ...       ...       ...       ...       ...       ...       ...       ...    ...           ...       ...\n",
       "404995                   80.0        6.0  4.256164  3.546172  0.000000  0.000000  2.257679  0.000000  0.000000  1.763428    0.0      0.000000         0\n",
       "404996                   80.0        6.0  3.509337  3.339451  0.000000  0.301030  2.887617  0.000000  0.000000  2.012837    0.0      0.000000         0\n",
       "404997                   80.0        6.0  4.814527  3.656098  0.000000  0.000000  2.747412  0.000000  2.654177  2.158362    0.0      0.000000         0\n",
       "404998                   80.0        6.0  3.364176  3.334051  0.000000  3.061075  3.186674  0.000000  2.133539  2.416641    0.0      0.000000         0\n",
       "404999                   80.0        6.0  3.603253  3.421439  0.000000  2.450249  2.725912  0.000000  2.307496  2.356026    0.0      0.000000         0\n",
       "\n",
       "[405000 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(columns=[\"BL1-A\", \"BL1-H\", \"BL1-W\", \"source\", \"stain\"]).reset_index(drop=True)\n",
    "df1[\"cfu_live\"] = (df1[\"percent_live\"] > 50.0).astype(int)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.groupby([\"inducer_concentration\", \"timepoint\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 27000, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array(list(df1[[\"inducer_concentration\", \n",
    "                        \"timepoint\"] + features].groupby([\"inducer_concentration\",\n",
    "                                                          \"timepoint\"]).apply(pd.DataFrame.to_numpy)))\n",
    "X1 = np.expand_dims(X1, axis=3)\n",
    "# drop the columns corresponding to inducer_concentration and timepoint\n",
    "X1 = X1[:, :, 2:, :]\n",
    "print(X1.shape)\n",
    "# display(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y1 = df1.groupby([\"inducer_concentration\", \"timepoint\"], as_index=False).first()[\"cfu_live\"].values\n",
    "display(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices of training samples: [5, 1, 7, 2, 10, 14, 11, 4, 8]\n",
      "indices of testing samples: [0, 3, 6, 9, 12, 13]\n",
      "shape of train matrix: (9, 27000, 9, 1)\n",
      "shape of test matrix: (6, 27000, 9, 1)\n",
      "\n",
      "shape of y1_train: (9,)\n",
      "shape of y1_test: (6,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test\n",
    "np.random.seed(5)\n",
    "train_idx = list(np.random.choice(len(X1), size=9, replace=False))\n",
    "test_idx = [x for x in list(range(len(X1))) if x not in train_idx]\n",
    "print(\"indices of training samples:\", train_idx)\n",
    "print(\"indices of testing samples:\", test_idx)\n",
    "X1_train = X1[train_idx]\n",
    "X1_test = X1[test_idx]\n",
    "print(\"shape of train matrix:\", X1_train.shape)\n",
    "print(\"shape of test matrix:\", X1_test.shape)\n",
    "print()\n",
    "y1_train = y1[train_idx]\n",
    "y1_test = y1[test_idx]\n",
    "print(\"shape of y1_train:\", y1_train.shape)\n",
    "print(\"shape of y1_test:\", y1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "model_input = Input(shape=X1_train[0].shape)\n",
    "\n",
    "# first convolution layer\n",
    "model_output = Conv2D(3, kernel_size=(1, X1_train.shape[2]),\n",
    "                 activation=None)(model_input)\n",
    "model_output = BatchNormalization()(model_output)\n",
    "model_output = Activation(\"relu\")(model_output)\n",
    "\n",
    "# sceond convolution layer\n",
    "model_output = Conv2D(3, (1, 1), activation=None)(model_output)\n",
    "model_output = BatchNormalization()(model_output)\n",
    "model_output = Activation(\"relu\")(model_output)\n",
    "\n",
    "# pooling layer\n",
    "model_output = AveragePooling2D(pool_size=(X1_train.shape[1], 1))(model_output)\n",
    "model_output = Flatten()(model_output)\n",
    "\n",
    "# Dense layer\n",
    "model_output = Dense(3, activation=None)(model_output)\n",
    "model_output = BatchNormalization()(model_output)\n",
    "model_output = Activation(\"relu\")(model_output)\n",
    "\n",
    "# output layer\n",
    "model_output = Dense(1, activation=None)(model_output)\n",
    "model_output = BatchNormalization()(model_output)\n",
    "model_output = Activation(\"sigmoid\")(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.6719 - accuracy: 0.5556 - val_loss: 0.6829 - val_accuracy: 0.5556\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6696 - accuracy: 0.5556 - val_loss: 0.6828 - val_accuracy: 0.5556\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6672 - accuracy: 0.5556 - val_loss: 0.6827 - val_accuracy: 0.5556\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6648 - accuracy: 0.5556 - val_loss: 0.6827 - val_accuracy: 0.5556\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6622 - accuracy: 0.5556 - val_loss: 0.6826 - val_accuracy: 0.5556\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6598 - accuracy: 0.5556 - val_loss: 0.6826 - val_accuracy: 0.5556\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6579 - accuracy: 0.5556 - val_loss: 0.6825 - val_accuracy: 0.5556\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6554 - accuracy: 0.5556 - val_loss: 0.6825 - val_accuracy: 0.5556\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6528 - accuracy: 0.5556 - val_loss: 0.6824 - val_accuracy: 0.5556\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6490 - accuracy: 0.5556 - val_loss: 0.6824 - val_accuracy: 0.5556\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6455 - accuracy: 0.5556 - val_loss: 0.6824 - val_accuracy: 0.4444\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6418 - accuracy: 0.5556 - val_loss: 0.6824 - val_accuracy: 0.4444\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6379 - accuracy: 0.5556 - val_loss: 0.6823 - val_accuracy: 0.4444\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6334 - accuracy: 0.5556 - val_loss: 0.6822 - val_accuracy: 0.4444\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6290 - accuracy: 0.5556 - val_loss: 0.6821 - val_accuracy: 0.4444\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6245 - accuracy: 0.5556 - val_loss: 0.6820 - val_accuracy: 0.4444\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6198 - accuracy: 0.5556 - val_loss: 0.6818 - val_accuracy: 0.4444\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6155 - accuracy: 0.5556 - val_loss: 0.6816 - val_accuracy: 0.4444\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6109 - accuracy: 0.5556 - val_loss: 0.6814 - val_accuracy: 0.3333\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6065 - accuracy: 0.5556 - val_loss: 0.6812 - val_accuracy: 0.3333\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6019 - accuracy: 0.5556 - val_loss: 0.6809 - val_accuracy: 0.6667\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5978 - accuracy: 0.5556 - val_loss: 0.6807 - val_accuracy: 0.6667\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5934 - accuracy: 0.5556 - val_loss: 0.6810 - val_accuracy: 0.6667\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5888 - accuracy: 0.5556 - val_loss: 0.6814 - val_accuracy: 0.6667\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5850 - accuracy: 0.5556 - val_loss: 0.6827 - val_accuracy: 0.6667\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5808 - accuracy: 0.5556 - val_loss: 0.6845 - val_accuracy: 0.6667\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5768 - accuracy: 0.6667 - val_loss: 0.6859 - val_accuracy: 0.6667\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5728 - accuracy: 0.6667 - val_loss: 0.6873 - val_accuracy: 0.6667\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5688 - accuracy: 0.7778 - val_loss: 0.6887 - val_accuracy: 0.6667\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5650 - accuracy: 0.7778 - val_loss: 0.6900 - val_accuracy: 0.6667\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5613 - accuracy: 0.7778 - val_loss: 0.6914 - val_accuracy: 0.6667\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5576 - accuracy: 0.7778 - val_loss: 0.6928 - val_accuracy: 0.5556\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5539 - accuracy: 0.7778 - val_loss: 0.6941 - val_accuracy: 0.5556\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5503 - accuracy: 0.7778 - val_loss: 0.6955 - val_accuracy: 0.4444\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5470 - accuracy: 0.7778 - val_loss: 0.6967 - val_accuracy: 0.1111\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5438 - accuracy: 0.7778 - val_loss: 0.6978 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5403 - accuracy: 0.8889 - val_loss: 0.6987 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5372 - accuracy: 0.8889 - val_loss: 0.6993 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5341 - accuracy: 0.8889 - val_loss: 0.6998 - val_accuracy: 0.1111\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5314 - accuracy: 0.8889 - val_loss: 0.7002 - val_accuracy: 0.2222\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5284 - accuracy: 0.8889 - val_loss: 0.7006 - val_accuracy: 0.2222\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5255 - accuracy: 0.8889 - val_loss: 0.7010 - val_accuracy: 0.2222\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5228 - accuracy: 0.8889 - val_loss: 0.7010 - val_accuracy: 0.2222\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5202 - accuracy: 0.8889 - val_loss: 0.7010 - val_accuracy: 0.2222\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5178 - accuracy: 0.8889 - val_loss: 0.7009 - val_accuracy: 0.2222\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5151 - accuracy: 0.8889 - val_loss: 0.7009 - val_accuracy: 0.2222\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5127 - accuracy: 0.8889 - val_loss: 0.7009 - val_accuracy: 0.2222\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5103 - accuracy: 0.8889 - val_loss: 0.7008 - val_accuracy: 0.2222\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5082 - accuracy: 0.8889 - val_loss: 0.7007 - val_accuracy: 0.2222\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5059 - accuracy: 0.8889 - val_loss: 0.7007 - val_accuracy: 0.3333\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5037 - accuracy: 0.8889 - val_loss: 0.7006 - val_accuracy: 0.3333\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5016 - accuracy: 0.8889 - val_loss: 0.7005 - val_accuracy: 0.3333\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4997 - accuracy: 0.8889 - val_loss: 0.7004 - val_accuracy: 0.3333\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4978 - accuracy: 0.8889 - val_loss: 0.7003 - val_accuracy: 0.3333\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4959 - accuracy: 0.8889 - val_loss: 0.7002 - val_accuracy: 0.4444\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4940 - accuracy: 0.8889 - val_loss: 0.7000 - val_accuracy: 0.4444\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4924 - accuracy: 0.8889 - val_loss: 0.6999 - val_accuracy: 0.4444\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4905 - accuracy: 0.8889 - val_loss: 0.6998 - val_accuracy: 0.5556\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4890 - accuracy: 0.8889 - val_loss: 0.6996 - val_accuracy: 0.5556\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4874 - accuracy: 0.8889 - val_loss: 0.6995 - val_accuracy: 0.5556\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4858 - accuracy: 0.8889 - val_loss: 0.6993 - val_accuracy: 0.5556\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4842 - accuracy: 0.8889 - val_loss: 0.6991 - val_accuracy: 0.5556\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4829 - accuracy: 0.8889 - val_loss: 0.6989 - val_accuracy: 0.5556\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4814 - accuracy: 0.8889 - val_loss: 0.6988 - val_accuracy: 0.5556\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4801 - accuracy: 0.8889 - val_loss: 0.6986 - val_accuracy: 0.5556\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4788 - accuracy: 0.8889 - val_loss: 0.6984 - val_accuracy: 0.5556\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4774 - accuracy: 0.8889 - val_loss: 0.6982 - val_accuracy: 0.5556\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4762 - accuracy: 0.8889 - val_loss: 0.6980 - val_accuracy: 0.5556\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4750 - accuracy: 0.8889 - val_loss: 0.6978 - val_accuracy: 0.5556\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4738 - accuracy: 0.8889 - val_loss: 0.6976 - val_accuracy: 0.5556\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4725 - accuracy: 0.8889 - val_loss: 0.6974 - val_accuracy: 0.5556\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4713 - accuracy: 0.8889 - val_loss: 0.6972 - val_accuracy: 0.5556\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4702 - accuracy: 0.8889 - val_loss: 0.6970 - val_accuracy: 0.5556\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4691 - accuracy: 0.8889 - val_loss: 0.6968 - val_accuracy: 0.5556\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4680 - accuracy: 0.8889 - val_loss: 0.6966 - val_accuracy: 0.5556\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4670 - accuracy: 0.8889 - val_loss: 0.6964 - val_accuracy: 0.5556\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4660 - accuracy: 0.8889 - val_loss: 0.6962 - val_accuracy: 0.5556\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4648 - accuracy: 0.8889 - val_loss: 0.6960 - val_accuracy: 0.5556\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4641 - accuracy: 0.8889 - val_loss: 0.6958 - val_accuracy: 0.5556\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4629 - accuracy: 0.8889 - val_loss: 0.6956 - val_accuracy: 0.5556\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4619 - accuracy: 0.8889 - val_loss: 0.6953 - val_accuracy: 0.5556\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4610 - accuracy: 0.8889 - val_loss: 0.6951 - val_accuracy: 0.5556\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4602 - accuracy: 0.8889 - val_loss: 0.6949 - val_accuracy: 0.5556\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4593 - accuracy: 0.8889 - val_loss: 0.6947 - val_accuracy: 0.5556\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4585 - accuracy: 0.8889 - val_loss: 0.6945 - val_accuracy: 0.5556\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4576 - accuracy: 0.8889 - val_loss: 0.6943 - val_accuracy: 0.5556\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4568 - accuracy: 0.8889 - val_loss: 0.6941 - val_accuracy: 0.5556\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4558 - accuracy: 0.8889 - val_loss: 0.6939 - val_accuracy: 0.5556\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4549 - accuracy: 0.8889 - val_loss: 0.6937 - val_accuracy: 0.5556\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4541 - accuracy: 0.8889 - val_loss: 0.6935 - val_accuracy: 0.5556\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4533 - accuracy: 0.8889 - val_loss: 0.6933 - val_accuracy: 0.5556\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4524 - accuracy: 0.8889 - val_loss: 0.6931 - val_accuracy: 0.5556\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4518 - accuracy: 0.8889 - val_loss: 0.6929 - val_accuracy: 0.5556\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4511 - accuracy: 0.8889 - val_loss: 0.6927 - val_accuracy: 0.5556\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4503 - accuracy: 0.8889 - val_loss: 0.6925 - val_accuracy: 0.5556\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4495 - accuracy: 0.8889 - val_loss: 0.6924 - val_accuracy: 0.5556\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4487 - accuracy: 0.8889 - val_loss: 0.6922 - val_accuracy: 0.5556\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4480 - accuracy: 0.8889 - val_loss: 0.6920 - val_accuracy: 0.5556\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4474 - accuracy: 0.8889 - val_loss: 0.6918 - val_accuracy: 0.5556\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4467 - accuracy: 0.8889 - val_loss: 0.6917 - val_accuracy: 0.5556\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4460 - accuracy: 0.8889 - val_loss: 0.6915 - val_accuracy: 0.5556\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4452 - accuracy: 0.8889 - val_loss: 0.6914 - val_accuracy: 0.5556\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4442 - accuracy: 0.8889 - val_loss: 0.6912 - val_accuracy: 0.5556\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4434 - accuracy: 0.8889 - val_loss: 0.6911 - val_accuracy: 0.5556\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4425 - accuracy: 0.8889 - val_loss: 0.6910 - val_accuracy: 0.5556\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4416 - accuracy: 0.8889 - val_loss: 0.6909 - val_accuracy: 0.5556\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4406 - accuracy: 0.8889 - val_loss: 0.6908 - val_accuracy: 0.5556\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4397 - accuracy: 0.8889 - val_loss: 0.6907 - val_accuracy: 0.5556\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4386 - accuracy: 0.8889 - val_loss: 0.6906 - val_accuracy: 0.5556\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4377 - accuracy: 0.8889 - val_loss: 0.6906 - val_accuracy: 0.5556\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4367 - accuracy: 0.8889 - val_loss: 0.6905 - val_accuracy: 0.5556\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4357 - accuracy: 0.8889 - val_loss: 0.6905 - val_accuracy: 0.5556\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4348 - accuracy: 0.8889 - val_loss: 0.6905 - val_accuracy: 0.5556\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4338 - accuracy: 0.8889 - val_loss: 0.6905 - val_accuracy: 0.5556\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4328 - accuracy: 0.8889 - val_loss: 0.6905 - val_accuracy: 0.5556\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4319 - accuracy: 0.8889 - val_loss: 0.6905 - val_accuracy: 0.5556\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4310 - accuracy: 0.8889 - val_loss: 0.6905 - val_accuracy: 0.5556\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4300 - accuracy: 0.8889 - val_loss: 0.6906 - val_accuracy: 0.5556\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4290 - accuracy: 0.8889 - val_loss: 0.6907 - val_accuracy: 0.5556\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4280 - accuracy: 0.8889 - val_loss: 0.6907 - val_accuracy: 0.5556\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4272 - accuracy: 0.8889 - val_loss: 0.6908 - val_accuracy: 0.5556\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4263 - accuracy: 0.8889 - val_loss: 0.6910 - val_accuracy: 0.5556\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4248 - accuracy: 0.8889 - val_loss: 0.6911 - val_accuracy: 0.5556\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4229 - accuracy: 0.8889 - val_loss: 0.6913 - val_accuracy: 0.5556\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4210 - accuracy: 0.8889 - val_loss: 0.6915 - val_accuracy: 0.5556\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4189 - accuracy: 0.8889 - val_loss: 0.6918 - val_accuracy: 0.5556\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4160 - accuracy: 0.8889 - val_loss: 0.6920 - val_accuracy: 0.5556\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4131 - accuracy: 0.8889 - val_loss: 0.6924 - val_accuracy: 0.5556\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4099 - accuracy: 0.8889 - val_loss: 0.6927 - val_accuracy: 0.5556\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4066 - accuracy: 0.8889 - val_loss: 0.6931 - val_accuracy: 0.5556\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4034 - accuracy: 0.8889 - val_loss: 0.6935 - val_accuracy: 0.5556\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4000 - accuracy: 0.8889 - val_loss: 0.6939 - val_accuracy: 0.5556\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3967 - accuracy: 0.8889 - val_loss: 0.6943 - val_accuracy: 0.5556\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3937 - accuracy: 0.8889 - val_loss: 0.6948 - val_accuracy: 0.5556\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3906 - accuracy: 0.8889 - val_loss: 0.6953 - val_accuracy: 0.5556\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3876 - accuracy: 0.8889 - val_loss: 0.6958 - val_accuracy: 0.5556\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3846 - accuracy: 0.8889 - val_loss: 0.6964 - val_accuracy: 0.5556\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3817 - accuracy: 0.8889 - val_loss: 0.6969 - val_accuracy: 0.5556\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3790 - accuracy: 0.8889 - val_loss: 0.6975 - val_accuracy: 0.5556\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3765 - accuracy: 0.8889 - val_loss: 0.6980 - val_accuracy: 0.5556\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3740 - accuracy: 0.8889 - val_loss: 0.6986 - val_accuracy: 0.5556\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3716 - accuracy: 0.8889 - val_loss: 0.6992 - val_accuracy: 0.5556\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3693 - accuracy: 0.8889 - val_loss: 0.6998 - val_accuracy: 0.5556\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3675 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.5556\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3655 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.5556\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3633 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.5556\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3613 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.5556\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3593 - accuracy: 1.0000 - val_loss: 0.7031 - val_accuracy: 0.5556\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3576 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.5556\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3561 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.5556\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3545 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.5556\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3532 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.5556\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3519 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.5556\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3506 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.5556\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3493 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.5556\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3483 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.5556\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3473 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.5556\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3462 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.5556\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3453 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.5556\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3443 - accuracy: 1.0000 - val_loss: 0.7109 - val_accuracy: 0.5556\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3435 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.5556\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3427 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.5556\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3419 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.5556\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3410 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.5556\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3406 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.5556\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3401 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.5556\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3396 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.5556\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3392 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.5556\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3388 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.5556\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3382 - accuracy: 1.0000 - val_loss: 0.7170 - val_accuracy: 0.5556\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3379 - accuracy: 1.0000 - val_loss: 0.7176 - val_accuracy: 0.5556\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3376 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.5556\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3371 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.5556\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3370 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3366 - accuracy: 1.0000 - val_loss: 0.7199 - val_accuracy: 0.5556\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3363 - accuracy: 1.0000 - val_loss: 0.7205 - val_accuracy: 0.5556\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3357 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.5556\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3353 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.5556\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3350 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.5556\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3348 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.5556\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3345 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.5556\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3342 - accuracy: 1.0000 - val_loss: 0.7239 - val_accuracy: 0.5556\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3339 - accuracy: 1.0000 - val_loss: 0.7245 - val_accuracy: 0.5556\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3336 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.5556\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3333 - accuracy: 1.0000 - val_loss: 0.7256 - val_accuracy: 0.5556\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3330 - accuracy: 1.0000 - val_loss: 0.7262 - val_accuracy: 0.5556\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3328 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.5556\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3325 - accuracy: 1.0000 - val_loss: 0.7274 - val_accuracy: 0.5556\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3322 - accuracy: 1.0000 - val_loss: 0.7279 - val_accuracy: 0.5556\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3320 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.5556\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3316 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.5556\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3314 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.5556\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3312 - accuracy: 1.0000 - val_loss: 0.7302 - val_accuracy: 0.5556\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3310 - accuracy: 1.0000 - val_loss: 0.7308 - val_accuracy: 0.5556\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3309 - accuracy: 1.0000 - val_loss: 0.7313 - val_accuracy: 0.5556\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3307 - accuracy: 1.0000 - val_loss: 0.7319 - val_accuracy: 0.5556\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3303 - accuracy: 1.0000 - val_loss: 0.7325 - val_accuracy: 0.5556\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3300 - accuracy: 1.0000 - val_loss: 0.7330 - val_accuracy: 0.5556\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3298 - accuracy: 1.0000 - val_loss: 0.7336 - val_accuracy: 0.5556\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3296 - accuracy: 1.0000 - val_loss: 0.7341 - val_accuracy: 0.5556\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3293 - accuracy: 1.0000 - val_loss: 0.7346 - val_accuracy: 0.5556\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3292 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.5556\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3291 - accuracy: 1.0000 - val_loss: 0.7357 - val_accuracy: 0.5556\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3288 - accuracy: 1.0000 - val_loss: 0.7362 - val_accuracy: 0.5556\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3284 - accuracy: 1.0000 - val_loss: 0.7367 - val_accuracy: 0.5556\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3282 - accuracy: 1.0000 - val_loss: 0.7372 - val_accuracy: 0.5556\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3280 - accuracy: 1.0000 - val_loss: 0.7377 - val_accuracy: 0.5556\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3278 - accuracy: 1.0000 - val_loss: 0.7382 - val_accuracy: 0.5556\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3276 - accuracy: 1.0000 - val_loss: 0.7387 - val_accuracy: 0.5556\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3274 - accuracy: 1.0000 - val_loss: 0.7391 - val_accuracy: 0.5556\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3272 - accuracy: 1.0000 - val_loss: 0.7396 - val_accuracy: 0.5556\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3270 - accuracy: 1.0000 - val_loss: 0.7401 - val_accuracy: 0.5556\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3267 - accuracy: 1.0000 - val_loss: 0.7405 - val_accuracy: 0.5556\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3266 - accuracy: 1.0000 - val_loss: 0.7409 - val_accuracy: 0.5556\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3264 - accuracy: 1.0000 - val_loss: 0.7413 - val_accuracy: 0.5556\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3263 - accuracy: 1.0000 - val_loss: 0.7417 - val_accuracy: 0.5556\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3261 - accuracy: 1.0000 - val_loss: 0.7421 - val_accuracy: 0.5556\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3259 - accuracy: 1.0000 - val_loss: 0.7425 - val_accuracy: 0.5556\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3258 - accuracy: 1.0000 - val_loss: 0.7429 - val_accuracy: 0.5556\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3257 - accuracy: 1.0000 - val_loss: 0.7432 - val_accuracy: 0.5556\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3254 - accuracy: 1.0000 - val_loss: 0.7436 - val_accuracy: 0.5556\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3253 - accuracy: 1.0000 - val_loss: 0.7439 - val_accuracy: 0.5556\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3252 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.5556\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3250 - accuracy: 1.0000 - val_loss: 0.7445 - val_accuracy: 0.5556\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3248 - accuracy: 1.0000 - val_loss: 0.7448 - val_accuracy: 0.5556\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3246 - accuracy: 1.0000 - val_loss: 0.7451 - val_accuracy: 0.5556\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3244 - accuracy: 1.0000 - val_loss: 0.7453 - val_accuracy: 0.5556\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3243 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.5556\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3241 - accuracy: 1.0000 - val_loss: 0.7457 - val_accuracy: 0.5556\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3239 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.5556\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3238 - accuracy: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.5556\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3236 - accuracy: 1.0000 - val_loss: 0.7463 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3235 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.5556\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3235 - accuracy: 1.0000 - val_loss: 0.7465 - val_accuracy: 0.5556\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3233 - accuracy: 1.0000 - val_loss: 0.7466 - val_accuracy: 0.5556\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3231 - accuracy: 1.0000 - val_loss: 0.7467 - val_accuracy: 0.5556\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3230 - accuracy: 1.0000 - val_loss: 0.7467 - val_accuracy: 0.5556\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3228 - accuracy: 1.0000 - val_loss: 0.7468 - val_accuracy: 0.5556\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3227 - accuracy: 1.0000 - val_loss: 0.7468 - val_accuracy: 0.5556\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3225 - accuracy: 1.0000 - val_loss: 0.7468 - val_accuracy: 0.5556\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3224 - accuracy: 1.0000 - val_loss: 0.7468 - val_accuracy: 0.5556\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3223 - accuracy: 1.0000 - val_loss: 0.7467 - val_accuracy: 0.5556\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3221 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.5556\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3221 - accuracy: 1.0000 - val_loss: 0.7441 - val_accuracy: 0.5556\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3219 - accuracy: 1.0000 - val_loss: 0.7426 - val_accuracy: 0.5556\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3218 - accuracy: 1.0000 - val_loss: 0.7411 - val_accuracy: 0.5556\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3216 - accuracy: 1.0000 - val_loss: 0.7396 - val_accuracy: 0.5556\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3215 - accuracy: 1.0000 - val_loss: 0.7381 - val_accuracy: 0.5556\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3214 - accuracy: 1.0000 - val_loss: 0.7365 - val_accuracy: 0.5556\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3213 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.5556\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3211 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.5556\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3210 - accuracy: 1.0000 - val_loss: 0.7316 - val_accuracy: 0.5556\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3209 - accuracy: 1.0000 - val_loss: 0.7299 - val_accuracy: 0.5556\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3208 - accuracy: 1.0000 - val_loss: 0.7282 - val_accuracy: 0.5556\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3207 - accuracy: 1.0000 - val_loss: 0.7265 - val_accuracy: 0.5556\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3206 - accuracy: 1.0000 - val_loss: 0.7247 - val_accuracy: 0.5556\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3205 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.5556\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3204 - accuracy: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.5556\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3203 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.5556\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3202 - accuracy: 1.0000 - val_loss: 0.7175 - val_accuracy: 0.5556\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3200 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.5556\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3199 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.5556\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3198 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.5556\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3197 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.5556\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3196 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.6667\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3196 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.6667\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3195 - accuracy: 1.0000 - val_loss: 0.7043 - val_accuracy: 0.6667\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3194 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.6667\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3193 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.6667\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3192 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.6667\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3191 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.6667\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3190 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.6667\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3188 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.6667\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3187 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.6667\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3186 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.6667\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3186 - accuracy: 1.0000 - val_loss: 0.6867 - val_accuracy: 0.6667\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3185 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.6667\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3184 - accuracy: 1.0000 - val_loss: 0.6828 - val_accuracy: 0.6667\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3183 - accuracy: 1.0000 - val_loss: 0.6808 - val_accuracy: 0.6667\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3182 - accuracy: 1.0000 - val_loss: 0.6789 - val_accuracy: 0.6667\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3181 - accuracy: 1.0000 - val_loss: 0.6769 - val_accuracy: 0.6667\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3180 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.6667\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3180 - accuracy: 1.0000 - val_loss: 0.6730 - val_accuracy: 0.6667\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3179 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.6667\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3178 - accuracy: 1.0000 - val_loss: 0.6691 - val_accuracy: 0.6667\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3177 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.6667\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3176 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.6667\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3175 - accuracy: 1.0000 - val_loss: 0.6633 - val_accuracy: 0.6667\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3174 - accuracy: 1.0000 - val_loss: 0.6614 - val_accuracy: 0.6667\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3173 - accuracy: 1.0000 - val_loss: 0.6595 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3173 - accuracy: 1.0000 - val_loss: 0.6576 - val_accuracy: 0.6667\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3172 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3171 - accuracy: 1.0000 - val_loss: 0.6539 - val_accuracy: 0.6667\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3170 - accuracy: 1.0000 - val_loss: 0.6520 - val_accuracy: 0.6667\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3170 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.6667\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3169 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 0.6667\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3168 - accuracy: 1.0000 - val_loss: 0.6465 - val_accuracy: 0.6667\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3167 - accuracy: 1.0000 - val_loss: 0.6447 - val_accuracy: 0.6667\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3166 - accuracy: 1.0000 - val_loss: 0.6429 - val_accuracy: 0.6667\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3166 - accuracy: 1.0000 - val_loss: 0.6412 - val_accuracy: 0.6667\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3165 - accuracy: 1.0000 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3164 - accuracy: 1.0000 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3163 - accuracy: 1.0000 - val_loss: 0.6359 - val_accuracy: 0.6667\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3162 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 0.6667\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3162 - accuracy: 1.0000 - val_loss: 0.6324 - val_accuracy: 0.6667\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3161 - accuracy: 1.0000 - val_loss: 0.6307 - val_accuracy: 0.6667\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3160 - accuracy: 1.0000 - val_loss: 0.6291 - val_accuracy: 0.6667\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3160 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 0.6667\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3159 - accuracy: 1.0000 - val_loss: 0.6257 - val_accuracy: 0.6667\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3158 - accuracy: 1.0000 - val_loss: 0.6241 - val_accuracy: 0.6667\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3158 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.6667\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3157 - accuracy: 1.0000 - val_loss: 0.6212 - val_accuracy: 0.6667\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3156 - accuracy: 1.0000 - val_loss: 0.6197 - val_accuracy: 0.6667\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3155 - accuracy: 1.0000 - val_loss: 0.6183 - val_accuracy: 0.6667\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3155 - accuracy: 1.0000 - val_loss: 0.6169 - val_accuracy: 0.6667\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3154 - accuracy: 1.0000 - val_loss: 0.6154 - val_accuracy: 0.6667\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3153 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.6667\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3153 - accuracy: 1.0000 - val_loss: 0.6125 - val_accuracy: 0.6667\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3152 - accuracy: 1.0000 - val_loss: 0.6111 - val_accuracy: 0.6667\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3151 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.6667\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3151 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.6667\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3150 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.6667\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3149 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.6667\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3149 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.6667\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3148 - accuracy: 1.0000 - val_loss: 0.6033 - val_accuracy: 0.6667\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3147 - accuracy: 1.0000 - val_loss: 0.6021 - val_accuracy: 0.6667\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3147 - accuracy: 1.0000 - val_loss: 0.6009 - val_accuracy: 0.6667\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3146 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.6667\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3145 - accuracy: 1.0000 - val_loss: 0.5984 - val_accuracy: 0.6667\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3145 - accuracy: 1.0000 - val_loss: 0.5972 - val_accuracy: 0.6667\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3144 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.6667\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3144 - accuracy: 1.0000 - val_loss: 0.5947 - val_accuracy: 0.6667\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3143 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.6667\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3142 - accuracy: 1.0000 - val_loss: 0.5922 - val_accuracy: 0.6667\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3142 - accuracy: 1.0000 - val_loss: 0.5909 - val_accuracy: 0.6667\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3141 - accuracy: 1.0000 - val_loss: 0.5897 - val_accuracy: 0.6667\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3140 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.6667\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3140 - accuracy: 1.0000 - val_loss: 0.5871 - val_accuracy: 0.6667\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3139 - accuracy: 1.0000 - val_loss: 0.5858 - val_accuracy: 0.6667\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3138 - accuracy: 1.0000 - val_loss: 0.5845 - val_accuracy: 0.6667\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3138 - accuracy: 1.0000 - val_loss: 0.5832 - val_accuracy: 0.6667\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3137 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.6667\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3136 - accuracy: 1.0000 - val_loss: 0.5806 - val_accuracy: 0.6667\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3136 - accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.6667\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3135 - accuracy: 1.0000 - val_loss: 0.5780 - val_accuracy: 0.6667\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3135 - accuracy: 1.0000 - val_loss: 0.5766 - val_accuracy: 0.6667\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3134 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.6667\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3134 - accuracy: 1.0000 - val_loss: 0.5740 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3133 - accuracy: 1.0000 - val_loss: 0.5727 - val_accuracy: 0.6667\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3132 - accuracy: 1.0000 - val_loss: 0.5713 - val_accuracy: 0.6667\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3132 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 0.6667\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3131 - accuracy: 1.0000 - val_loss: 0.5686 - val_accuracy: 0.6667\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3131 - accuracy: 1.0000 - val_loss: 0.5673 - val_accuracy: 0.6667\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3130 - accuracy: 1.0000 - val_loss: 0.5659 - val_accuracy: 0.6667\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3129 - accuracy: 1.0000 - val_loss: 0.5646 - val_accuracy: 0.6667\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3129 - accuracy: 1.0000 - val_loss: 0.5633 - val_accuracy: 0.6667\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3128 - accuracy: 1.0000 - val_loss: 0.5619 - val_accuracy: 0.6667\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3128 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.6667\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3127 - accuracy: 1.0000 - val_loss: 0.5591 - val_accuracy: 0.6667\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3126 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.6667\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3126 - accuracy: 1.0000 - val_loss: 0.5564 - val_accuracy: 0.6667\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3125 - accuracy: 1.0000 - val_loss: 0.5551 - val_accuracy: 0.6667\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3125 - accuracy: 1.0000 - val_loss: 0.5537 - val_accuracy: 0.6667\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3124 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.6667\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3124 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.6667\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3123 - accuracy: 1.0000 - val_loss: 0.5493 - val_accuracy: 0.6667\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3122 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.6667\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3122 - accuracy: 1.0000 - val_loss: 0.5441 - val_accuracy: 0.6667\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3121 - accuracy: 1.0000 - val_loss: 0.5416 - val_accuracy: 0.6667\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3121 - accuracy: 1.0000 - val_loss: 0.5391 - val_accuracy: 0.6667\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3120 - accuracy: 1.0000 - val_loss: 0.5366 - val_accuracy: 0.6667\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3120 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.6667\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3119 - accuracy: 1.0000 - val_loss: 0.5315 - val_accuracy: 0.6667\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3119 - accuracy: 1.0000 - val_loss: 0.5289 - val_accuracy: 0.6667\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3118 - accuracy: 1.0000 - val_loss: 0.5264 - val_accuracy: 0.6667\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3117 - accuracy: 1.0000 - val_loss: 0.5238 - val_accuracy: 0.6667\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3117 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.6667\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3116 - accuracy: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.6667\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3116 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.6667\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3115 - accuracy: 1.0000 - val_loss: 0.5136 - val_accuracy: 0.6667\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3115 - accuracy: 1.0000 - val_loss: 0.5101 - val_accuracy: 0.6667\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3114 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.6667\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3114 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.6667\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3113 - accuracy: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.6667\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3112 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.6667\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3112 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.6667\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3111 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.7778\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3111 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.7778\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3110 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.7778\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3110 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.7778\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3109 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.7778\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3109 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.7778\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3108 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.7778\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3108 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.7778\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3107 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.7778\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3107 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.7778\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3106 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.7778\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3105 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.7778\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3105 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.7778\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3104 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.7778\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3104 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.7778\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3103 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.7778\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3103 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.7778\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3102 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.7778\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3102 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.7778\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3101 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3101 - accuracy: 1.0000 - val_loss: 0.4176 - val_accuracy: 0.8889\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3100 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.8889\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3100 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3099 - accuracy: 1.0000 - val_loss: 0.4081 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3099 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3098 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3098 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3097 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3097 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3096 - accuracy: 1.0000 - val_loss: 0.3905 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3096 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3095 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3094 - accuracy: 1.0000 - val_loss: 0.3821 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3094 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3094 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3093 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3092 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3092 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3091 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3091 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3090 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3090 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3089 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3089 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3088 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3088 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3088 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3087 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3087 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3086 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3085 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3085 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3084 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3084 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3084 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3083 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3082 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3082 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3082 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3081 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3081 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3080 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3080 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3079 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3079 - accuracy: 1.0000 - val_loss: 0.3421 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3078 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3078 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3077 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3077 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3076 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3076 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3075 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3075 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3074 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3074 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3073 - accuracy: 1.0000 - val_loss: 0.3483 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3073 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3072 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3072 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3071 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3071 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3071 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3070 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3069 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3069 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3069 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3068 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3068 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3067 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3067 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3066 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3066 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3065 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3065 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3064 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3064 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3063 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3063 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3062 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3062 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3061 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3061 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3061 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3060 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3060 - accuracy: 1.0000 - val_loss: 0.3671 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3059 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3059 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3058 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3058 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3057 - accuracy: 1.0000 - val_loss: 0.3706 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3057 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3056 - accuracy: 1.0000 - val_loss: 0.3721 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3056 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3056 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9dda8714a8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify input and output\n",
    "model = Model(inputs=[model_input],\n",
    "              outputs=model_output)\n",
    "\n",
    "# define loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# save the best performing model\n",
    "checkpointer = ModelCheckpoint(filepath='Result/saved_weights.hdf5', \n",
    "                               monitor='val_loss', verbose=0, \n",
    "                               save_best_only=True)\n",
    "\n",
    "# model training\n",
    "model.fit([X1_train], y1_train,\n",
    "          batch_size=60,\n",
    "          epochs=500, \n",
    "          verbose=1,\n",
    "          callbacks=[checkpointer],\n",
    "          validation_data=([X1_train], y1_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # load final model\n",
    "# final_model = load_model('Data/Final_weights.hdf5')\n",
    "\n",
    "# generate ROC and AUC\n",
    "y_scores = model.predict([X1_test])\n",
    "fpr, tpr, _ = roc_curve(y1_test, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC = {0:.2f}'.format(roc_auc))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "1. Increase number of samples from 15 --> 60, and potentially split by replicates (if exist) to make even more samples\n",
    "2. Figure out how to see which cells in each sample activate which CNN filters.\n",
    "3. Predict other values (see below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: sample-level prediction of live/dead based on stain value majority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: sample-level prediction of concentration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: sample-level prediction of CFU percent_live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pysd2cat] *",
   "language": "python",
   "name": "conda-env-pysd2cat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
